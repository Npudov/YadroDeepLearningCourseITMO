{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Реализовать с помощью `Numpy` класс `MyMLP`, моделирующий работу полносвязной нейронной сети.\n",
        "\n",
        "Реализуемый класс должен\n",
        "\n",
        "1. Поддерживать создание любого числа слоев с любым числом нейронов. Тип инициализации весов не регламентируется.\n",
        "2. Обеспечивать выбор следующих функции активации в рамках каждого слоя: `ReLU`, `sigmoid`, `linear`.\n",
        "3. Поддерживать решение задачи классификации и регрессии (выбор соответствующего лосса, в том числе для задачи многоклассовой классификации).\n",
        "4. В процессе обучения использовать самостоятельно реализованный механизм обратного распространения (вывод формул в формате markdown) для применения градиентного и стохастического градиентного спусков (с выбором размера батча)\n",
        "5. Поддерживать использование `l1`, `l2` и `l1l2` регуляризаций."
      ],
      "metadata": {
        "id": "GnNzcz8_ZjVO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Самостоятельно выбрать наборы данных (классификация и регрессия). Провести эксперименты (различные конфигурации сети: количество слоев, нейронов, функции активации, скорость обучения и тп. — минимум 5 различных конфигураций) и сравнить результаты работы (оценка качества модели + время обучения и инференса) реализованного класса `MyMLP` со следующими моделям (в одинаковых конфигурациях):\n",
        "\n",
        "*   MLPClassifier/MLPRegressor из sklearn\n",
        "*   TensorFlow\n",
        "*   Keras\n",
        "*   PyTorch\n",
        "\n",
        "Результат представить в виде .ipynb блокнота, содержащего весь необходимый код и визуализации сравнения реализаций для рассмотренных конфигураций.\n"
      ],
      "metadata": {
        "id": "xTRKg7mlcJBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "YTy4r4w-XqT7"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class MyMLPLayer:\n",
        "    def __init__(self, input_size, output_size, activation):\n",
        "        self.weights = np.random.randn(input_size, output_size) * np.sqrt(2. / input_size)  # He initialization\n",
        "        self.biases = np.zeros((1, output_size))\n",
        "        self.activation_name = activation\n",
        "\n",
        "    def activate(self, x):\n",
        "        if self.activation_name == 'relu':\n",
        "            return np.maximum(0, x)\n",
        "        elif self.activation_name == 'sigmoid':\n",
        "            return 1 / (1 + np.exp(-x))\n",
        "        elif self.activation_name == 'linear':\n",
        "            return x\n",
        "        elif self.activation_name == 'softmax':\n",
        "            exps = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "            return exps / np.sum(exps, axis=1, keepdims=True)\n",
        "\n",
        "    def activation_derivative(self, x):\n",
        "        if self.activation_name == 'relu':\n",
        "            return (x > 0).astype(float)\n",
        "        elif self.activation_name == 'sigmoid':\n",
        "            sig = 1 / (1 + np.exp(-x))\n",
        "            return sig * (1 - sig)\n",
        "        elif self.activation_name == 'linear':\n",
        "            return np.ones_like(x)\n",
        "        elif self.activation_name == 'softmax':\n",
        "            # For softmax, this is not used directly in backprop\n",
        "            return np.ones_like(x)\n",
        "\n",
        "class MyMLP:\n",
        "    def __init__(self, layers_config, learning_rate=0.01, task='classification', loss='cross_entropy',\n",
        "                 reg=None, reg_lambda=0.0):\n",
        "        self.layers = []\n",
        "        for i in range(len(layers_config) - 1):\n",
        "            input_size = layers_config[i][0]\n",
        "            output_size = layers_config[i+1][0]\n",
        "            activation = layers_config[i+1][1]\n",
        "\n",
        "            # For classification, last layer should be softmax if cross_entropy\n",
        "            if i == len(layers_config)-2 and task == 'classification' and loss == 'cross_entropy':\n",
        "                activation = 'softmax'\n",
        "\n",
        "            self.layers.append(MyMLPLayer(input_size, output_size, activation))\n",
        "\n",
        "        self.learning_rate = learning_rate\n",
        "        self.task = task\n",
        "        self.loss_name = loss\n",
        "        self.reg = reg\n",
        "        self.reg_lambda = reg_lambda\n",
        "\n",
        "    def _loss(self, y_true, y_pred):\n",
        "        m = y_true.shape[0]\n",
        "        if self.loss_name == 'cross_entropy':\n",
        "            eps = 1e-15\n",
        "            y_pred = np.clip(y_pred, eps, 1 - eps)\n",
        "            return -np.mean(np.sum(y_true * np.log(y_pred), axis=1))\n",
        "        elif self.loss_name == 'mse':\n",
        "            return np.mean((y_true - y_pred) ** 2)\n",
        "\n",
        "    def _loss_derivative(self, y_true, y_pred):\n",
        "        if self.loss_name == 'cross_entropy':\n",
        "            # For softmax + cross_entropy, the derivative is simply y_pred - y_true\n",
        "            return y_pred - y_true\n",
        "        elif self.loss_name == 'mse':\n",
        "            return 2 * (y_pred - y_true) / y_true.shape[0]\n",
        "\n",
        "    def _apply_regularization(self, grad_w, weights):\n",
        "        if self.reg == 'l1':\n",
        "            return grad_w + self.reg_lambda * np.sign(weights)\n",
        "        elif self.reg == 'l2':\n",
        "            return grad_w + 2 * self.reg_lambda * weights\n",
        "        elif self.reg == 'l1l2':\n",
        "            return grad_w + self.reg_lambda * np.sign(weights) + 2 * self.reg_lambda * weights\n",
        "        else:\n",
        "            return grad_w\n",
        "\n",
        "    def forward(self, X):\n",
        "        activations = [X]\n",
        "        pre_activations = []\n",
        "        a = X\n",
        "        for layer in self.layers:\n",
        "            z = np.dot(a, layer.weights) + layer.biases\n",
        "            a = layer.activate(z)\n",
        "            pre_activations.append(z)\n",
        "            activations.append(a)\n",
        "        return activations, pre_activations\n",
        "\n",
        "    def backward(self, activations, pre_activations, y_true):\n",
        "        grads = []\n",
        "        m = y_true.shape[0]\n",
        "\n",
        "        # Output layer\n",
        "        delta = self._loss_derivative(y_true, activations[-1])\n",
        "\n",
        "        # For softmax activation in output layer, we don't multiply by activation derivative\n",
        "        if self.layers[-1].activation_name != 'softmax':\n",
        "            delta *= self.layers[-1].activation_derivative(pre_activations[-1])\n",
        "\n",
        "        for i in reversed(range(len(self.layers))):\n",
        "            a_prev = activations[i]\n",
        "            dw = np.dot(a_prev.T, delta) / m\n",
        "            db = np.sum(delta, axis=0, keepdims=True) / m\n",
        "            dw = self._apply_regularization(dw, self.layers[i].weights)\n",
        "\n",
        "            grads.insert(0, (dw, db))\n",
        "\n",
        "            if i > 0:\n",
        "                delta = np.dot(delta, self.layers[i].weights.T) * \\\n",
        "                        self.layers[i-1].activation_derivative(pre_activations[i-1])\n",
        "\n",
        "        return grads\n",
        "\n",
        "    def update_params(self, grads):\n",
        "        for i, (dw, db) in enumerate(grads):\n",
        "            self.layers[i].weights -= self.learning_rate * dw\n",
        "            self.layers[i].biases -= self.learning_rate * db\n",
        "\n",
        "    def fit(self, X, y, epochs=100, batch_size=32, verbose=False):\n",
        "        m = X.shape[0]\n",
        "        for epoch in range(epochs):\n",
        "            indices = np.arange(m)\n",
        "            np.random.shuffle(indices)\n",
        "            for i in range(0, m, batch_size):\n",
        "                batch_end = min(i + batch_size, m)\n",
        "                X_batch = X[indices[i:batch_end]]\n",
        "                y_batch = y[indices[i:batch_end]]\n",
        "\n",
        "                activations, pre_activations = self.forward(X_batch)\n",
        "                grads = self.backward(activations, pre_activations, y_batch)\n",
        "                self.update_params(grads)\n",
        "\n",
        "            if verbose and epoch % 10 == 0:\n",
        "                activations, _ = self.forward(X)\n",
        "                loss = self._loss(y, activations[-1])\n",
        "                print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
        "\n",
        "    def predict(self, X):\n",
        "        activations, _ = self.forward(X)\n",
        "        output = activations[-1]\n",
        "        if self.task == 'classification':\n",
        "            return np.argmax(output, axis=1)\n",
        "        else:\n",
        "            return output\n",
        "\n",
        "    def evaluate(self, X, y):\n",
        "        pred = self.predict(X)\n",
        "        if self.task == 'classification':\n",
        "            true = np.argmax(y, axis=1)\n",
        "            return np.mean(pred == true)\n",
        "        else:\n",
        "            return np.mean((pred - y) ** 2)"
      ],
      "metadata": {
        "id": "HkqYNbcsfPtk"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Теория: Прямой и обратный проход в `MyMLP`\n",
        "\n",
        "---\n",
        "\n",
        "### **1. Прямой проход (Forward pass)**\n",
        "\n",
        "Для каждого слоя $l$ с входом $A^{(l-1)}$, весами $W^{(l)}$, смещением $b^{(l)}$:\n",
        "\n",
        "$$\n",
        "Z^{(l)} = A^{(l-1)} W^{(l)} + b^{(l)}\n",
        "$$\n",
        "\n",
        "$$\n",
        "A^{(l)} = f(Z^{(l)})\n",
        "$$\n",
        "\n",
        "где $f \\in \\{ \\text{ReLU}, \\text{Sigmoid}, \\text{Linear} \\}$\n",
        "\n",
        "---\n",
        "\n",
        "### **2. Функции активации**\n",
        "\n",
        "- **ReLU**:\n",
        "  $$\n",
        "  f(z) = \\max(0, z), \\quad f'(z) =\n",
        "  \\begin{cases}\n",
        "  1, & z > 0 \\\\\n",
        "  0, & z \\leq 0\n",
        "  \\end{cases}\n",
        "  $$\n",
        "\n",
        "- **Sigmoid**:\n",
        "  $$\n",
        "  f(z) = \\frac{1}{1 + e^{-z}}, \\quad f'(z) = f(z)(1 - f(z))\n",
        "  $$\n",
        "\n",
        "- **Linear**:\n",
        "  $$\n",
        "  f(z) = z, \\quad f'(z) = 1\n",
        "  $$\n",
        "\n",
        "---\n",
        "\n",
        "### **3. Функции потерь**\n",
        "\n",
        "- **Классификация (Cross-Entropy)**:\n",
        "  $$\n",
        "  \\mathcal{L} = -\\frac{1}{m} \\sum_{i=1}^m \\sum_{k=1}^{K} y_{ik} \\log(\\hat{y}_{ik})\n",
        "  $$\n",
        "\n",
        "- **Регрессия (MSE)**:\n",
        "  $$\n",
        "  \\mathcal{L} = \\frac{1}{m} \\sum_{i=1}^m (y_i - \\hat{y}_i)^2\n",
        "  $$\n",
        "\n",
        "---\n",
        "\n",
        "### **4. Обратное распространение ошибки (Backpropagation)**\n",
        "\n",
        "Пусть:\n",
        "\n",
        "- $\\delta^{(l)}$ — градиент ошибки на слое $l$\n",
        "- $\\eta$ — скорость обучения\n",
        "- $m$ — размер батча\n",
        "- $\\lambda$ — коэффициент регуляризации\n",
        "\n",
        "#### Выходной слой:\n",
        "\n",
        "- **Регрессия (MSE)**:\n",
        "  $$\n",
        "  \\delta^{(L)} = 2(\\hat{y} - y) \\cdot f'(Z^{(L)})\n",
        "  $$\n",
        "\n",
        "- **Классификация (Softmax + Cross-Entropy)**:\n",
        "  $$\n",
        "  \\delta^{(L)} = \\hat{y} - y\n",
        "  $$\n",
        "\n",
        "#### Скрытые слои $l = L-1, \\dots, 1$:\n",
        "\n",
        "$$\n",
        "\\delta^{(l)} = \\left( \\delta^{(l+1)} {W^{(l+1)}}^T \\right) \\cdot f'(Z^{(l)})\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "### **5. Обновление весов (Gradient Descent + Regularization)**\n",
        "\n",
        "#### L2-регуляризация:\n",
        "\n",
        "$$\n",
        "W^{(l)} := W^{(l)} - \\eta \\left( \\frac{1}{m} {A^{(l-1)}}^T \\delta^{(l)} + 2\\lambda W^{(l)} \\right)\n",
        "$$\n",
        "\n",
        "#### L1-регуляризация:\n",
        "\n",
        "$$\n",
        "W^{(l)} := W^{(l)} - \\eta \\left( \\frac{1}{m} {A^{(l-1)}}^T \\delta^{(l)} + \\lambda \\cdot \\text{sign}(W^{(l)}) \\right)\n",
        "$$\n",
        "\n",
        "#### L1 + L2 (Elastic Net):\n",
        "\n",
        "$$\n",
        "W^{(l)} := W^{(l)} - \\eta \\left( \\frac{1}{m} {A^{(l-1)}}^T \\delta^{(l)} + \\lambda \\left( \\text{sign}(W^{(l)}) + 2W^{(l)} \\right) \\right)\n",
        "$$\n",
        "\n",
        "Аналогично обновляются смещения $b^{(l)}$:\n",
        "\n",
        "$$\n",
        "b^{(l)} := b^{(l)} - \\eta \\cdot \\text{mean}(\\delta^{(l)})\n",
        "$$\n"
      ],
      "metadata": {
        "id": "qjTyLrqSZcX_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Эксперименты"
      ],
      "metadata": {
        "id": "oBS-a9PiCvyU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "from sklearn.datasets import load_iris, load_diabetes, fetch_california_housing, make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "te3e6Mlj79qu"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "3civ6b6I2pTn"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Классификация — Iris\n",
        "iris = load_iris()\n",
        "X_class, y_class = iris.data, iris.target\n",
        "X_class = StandardScaler().fit_transform(X_class)\n",
        "y_class_oh = OneHotEncoder(sparse_output=False).fit_transform(y_class.reshape(-1, 1))\n",
        "Xc_train, Xc_test, yc_train, yc_test = train_test_split(X_class, y_class_oh, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "SEZ02uGBC3_E"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "configs = [\n",
        "    {'layers': [(4,), (10, 'relu'), (3, 'softmax')], 'lr': 0.01},\n",
        "    {'layers': [(4,), (16, 'relu'), (16, 'relu'), (3, 'softmax')], 'lr': 0.005},\n",
        "    {'layers': [(4,), (8, 'sigmoid'), (3, 'softmax')], 'lr': 0.01},\n",
        "    {'layers': [(4,), (20, 'relu'), (10, 'sigmoid'), (3, 'softmax')], 'lr': 0.001},\n",
        "    {'layers': [(4,), (32, 'relu'), (32, 'relu'), (3, 'softmax')], 'lr': 0.01}\n",
        "]"
      ],
      "metadata": {
        "id": "81Q_duZUDl-M"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from copy import deepcopy\n",
        "\n",
        "results = []\n",
        "\n",
        "for config_idx, cfg in enumerate(configs):\n",
        "    print(f\"\\nКонфигурация #{config_idx+1}\")\n",
        "    print(\"Архитектура:\", cfg['layers'])\n",
        "    print(\"Learning rate:\", cfg['lr'])\n",
        "\n",
        "    # MyMLP\n",
        "    try:\n",
        "        mymlp = MyMLP(deepcopy(cfg['layers']), learning_rate=cfg['lr'],\n",
        "                     task='classification', loss='cross_entropy')\n",
        "\n",
        "        # Обучение\n",
        "        t0 = time.time()\n",
        "        mymlp.fit(Xc_train, yc_train, epochs=100, batch_size=16)\n",
        "        t1 = time.time()\n",
        "        my_train_time = t1 - t0\n",
        "\n",
        "        # Инференс\n",
        "        t0_inf = time.time()\n",
        "        my_acc = mymlp.evaluate(Xc_test, yc_test)\n",
        "        t1_inf = time.time()\n",
        "        my_inf_time = t1_inf - t0_inf\n",
        "\n",
        "        print(f\"MyMLP Accuracy: {my_acc:.4f}, Train Time: {my_train_time:.2f}s, Inference Time: {my_inf_time:.4f}s\")\n",
        "    except Exception as e:\n",
        "        print(f\"MyMLP failed: {str(e)}\")\n",
        "        my_acc, my_train_time, my_inf_time = np.nan, np.nan, np.nan\n",
        "\n",
        "    # Sklearn\n",
        "    try:\n",
        "        hidden_layers = tuple(layer[0] for layer in cfg['layers'][1:-1])\n",
        "        sk_mlp = MLPClassifier(hidden_layer_sizes=hidden_layers,\n",
        "                             activation='relu',\n",
        "                             learning_rate_init=cfg['lr'],\n",
        "                             max_iter=100,\n",
        "                             random_state=42)\n",
        "\n",
        "        # Обучение\n",
        "        t0 = time.time()\n",
        "        sk_mlp.fit(Xc_train, np.argmax(yc_train, axis=1))\n",
        "        t1 = time.time()\n",
        "        sk_train_time = t1 - t0\n",
        "\n",
        "        # Инференс\n",
        "        t0_inf = time.time()\n",
        "        sk_acc = sk_mlp.score(Xc_test, np.argmax(yc_test, axis=1))\n",
        "        t1_inf = time.time()\n",
        "        sk_inf_time = t1_inf - t0_inf\n",
        "\n",
        "        print(f\"Sklearn Accuracy: {sk_acc:.4f}, Train Time: {sk_train_time:.2f}s, Inference Time: {sk_inf_time:.4f}s\")\n",
        "    except Exception as e:\n",
        "        print(f\"Sklearn failed: {str(e)}\")\n",
        "        sk_acc, sk_train_time, sk_inf_time = np.nan, np.nan, np.nan\n",
        "\n",
        "    # TensorFlow\n",
        "    try:\n",
        "        tf_model = Sequential()\n",
        "        for i, (units, act) in enumerate(cfg['layers'][1:]):\n",
        "            activation = 'softmax' if i == len(cfg['layers'])-2 else \\\n",
        "                       'sigmoid' if act == 'sigmoid' else \\\n",
        "                       'relu' if act == 'relu' else 'linear'\n",
        "            tf_model.add(Dense(units, activation=activation,\n",
        "                             input_dim=cfg['layers'][i][0] if i == 0 else None))\n",
        "        tf_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=cfg['lr']),\n",
        "                       loss='categorical_crossentropy',\n",
        "                       metrics=['accuracy'])\n",
        "\n",
        "        # Обучение\n",
        "        t0 = time.time()\n",
        "        tf_model.fit(Xc_train, yc_train, epochs=100, verbose=0, batch_size=16)\n",
        "        t1 = time.time()\n",
        "        tf_train_time = t1 - t0\n",
        "\n",
        "        # Инференс\n",
        "        t0_inf = time.time()\n",
        "        _, tf_acc = tf_model.evaluate(Xc_test, yc_test, verbose=0)\n",
        "        t1_inf = time.time()\n",
        "        tf_inf_time = t1_inf - t0_inf\n",
        "\n",
        "        print(f\"TensorFlow Accuracy: {tf_acc:.4f}, Train Time: {tf_train_time:.2f}s, Inference Time: {tf_inf_time:.4f}s\")\n",
        "    except Exception as e:\n",
        "        print(f\"TensorFlow failed: {str(e)}\")\n",
        "        tf_acc, tf_train_time, tf_inf_time = np.nan, np.nan, np.nan\n",
        "\n",
        "    # Keras\n",
        "    try:\n",
        "        keras_model = Sequential()\n",
        "        for i, (units, act) in enumerate(cfg['layers'][1:]):\n",
        "            activation = 'softmax' if i == len(cfg['layers'])-2 else \\\n",
        "                       'sigmoid' if act == 'sigmoid' else \\\n",
        "                       'relu' if act == 'relu' else 'linear'\n",
        "            keras_model.add(Dense(units, activation=activation,\n",
        "                               input_dim=cfg['layers'][i][0] if i == 0 else None))\n",
        "        keras_model.compile(optimizer=Adam(learning_rate=cfg['lr']),\n",
        "                         loss='categorical_crossentropy',\n",
        "                         metrics=['accuracy'])\n",
        "\n",
        "        # Обучение\n",
        "        t0 = time.time()\n",
        "        keras_model.fit(Xc_train, yc_train, epochs=100, verbose=0, batch_size=16)\n",
        "        t1 = time.time()\n",
        "        keras_train_time = t1 - t0\n",
        "\n",
        "        # Инференс\n",
        "        t0_inf = time.time()\n",
        "        _, keras_acc = keras_model.evaluate(Xc_test, yc_test, verbose=0)\n",
        "        t1_inf = time.time()\n",
        "        keras_inf_time = t1_inf - t0_inf\n",
        "\n",
        "        print(f\"Keras Accuracy: {keras_acc:.4f}, Train Time: {keras_train_time:.2f}s, Inference Time: {keras_inf_time:.4f}s\")\n",
        "    except Exception as e:\n",
        "        print(f\"Keras failed: {str(e)}\")\n",
        "        keras_acc, keras_train_time, keras_inf_time = np.nan, np.nan, np.nan\n",
        "\n",
        "    # PyTorch\n",
        "    try:\n",
        "        class TorchNet(nn.Module):\n",
        "            def __init__(self, layers_cfg):\n",
        "                super(TorchNet, self).__init__()\n",
        "                self.layers = nn.ModuleList()\n",
        "                for i in range(1, len(layers_cfg)):\n",
        "                    in_dim = layers_cfg[i-1][0]\n",
        "                    out_dim = layers_cfg[i][0]\n",
        "                    self.layers.append(nn.Linear(in_dim, out_dim))\n",
        "                    if i < len(layers_cfg)-1:\n",
        "                        act = layers_cfg[i][1]\n",
        "                        if act == 'relu':\n",
        "                            self.layers.append(nn.ReLU())\n",
        "                        elif act == 'sigmoid':\n",
        "                            self.layers.append(nn.Sigmoid())\n",
        "\n",
        "            def forward(self, x):\n",
        "                for layer in self.layers:\n",
        "                    x = layer(x)\n",
        "                return x\n",
        "\n",
        "        torch_model = TorchNet(cfg['layers'])\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.Adam(torch_model.parameters(), lr=cfg['lr'])\n",
        "\n",
        "        X_train_tensor = torch.tensor(Xc_train, dtype=torch.float32)\n",
        "        y_train_tensor = torch.tensor(np.argmax(yc_train, axis=1), dtype=torch.long)\n",
        "        X_test_tensor = torch.tensor(Xc_test, dtype=torch.float32)\n",
        "        y_test_tensor = torch.tensor(np.argmax(yc_test, axis=1), dtype=torch.long)\n",
        "\n",
        "        # Обучение\n",
        "        t0 = time.time()\n",
        "        for epoch in range(100):\n",
        "            optimizer.zero_grad()\n",
        "            outputs = torch_model(X_train_tensor)\n",
        "            loss = criterion(outputs, y_train_tensor)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        t1 = time.time()\n",
        "        torch_train_time = t1 - t0\n",
        "\n",
        "        # Инференс\n",
        "        with torch.no_grad():\n",
        "            t0_inf = time.time()\n",
        "            pred = torch_model(X_test_tensor)\n",
        "            _, predicted = torch.max(pred, 1)\n",
        "            torch_acc = (predicted == y_test_tensor).float().mean().item()\n",
        "            t1_inf = time.time()\n",
        "            torch_inf_time = t1_inf - t0_inf\n",
        "\n",
        "        print(f\"PyTorch Accuracy: {torch_acc:.4f}, Train Time: {torch_train_time:.2f}s, Inference Time: {torch_inf_time:.4f}s\")\n",
        "    except Exception as e:\n",
        "        print(f\"PyTorch failed: {str(e)}\")\n",
        "        torch_acc, torch_train_time, torch_inf_time = np.nan, np.nan, np.nan\n",
        "\n",
        "    # === Сбор результатов ===\n",
        "    results.append({\n",
        "        'Model': 'MyMLP',\n",
        "        'Config': f'{config_idx+1}',\n",
        "        'Accuracy': my_acc,\n",
        "        'Train Time (s)': my_train_time,\n",
        "        'Inference Time (s)': my_inf_time\n",
        "    })\n",
        "    results.append({\n",
        "        'Model': 'Sklearn',\n",
        "        'Config': f'{config_idx+1}',\n",
        "        'Accuracy': sk_acc,\n",
        "        'Train Time (s)': sk_train_time,\n",
        "        'Inference Time (s)': sk_inf_time\n",
        "    })\n",
        "    results.append({\n",
        "        'Model': 'TensorFlow',\n",
        "        'Config': f'{config_idx+1}',\n",
        "        'Accuracy': tf_acc,\n",
        "        'Train Time (s)': tf_train_time,\n",
        "        'Inference Time (s)': tf_inf_time\n",
        "    })\n",
        "    results.append({\n",
        "        'Model': 'Keras',\n",
        "        'Config': f'{config_idx+1}',\n",
        "        'Accuracy': keras_acc,\n",
        "        'Train Time (s)': keras_train_time,\n",
        "        'Inference Time (s)': keras_inf_time\n",
        "    })\n",
        "    results.append({\n",
        "        'Model': 'PyTorch',\n",
        "        'Config': f'{config_idx+1}',\n",
        "        'Accuracy': torch_acc,\n",
        "        'Train Time (s)': torch_train_time,\n",
        "        'Inference Time (s)': torch_inf_time\n",
        "    })"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAjFEd8jEG4V",
        "outputId": "a09badef-c0de-4a09-e94e-ee8f40452522"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Конфигурация #1\n",
            "Архитектура: [(4,), (10, 'relu'), (3, 'softmax')]\n",
            "Learning rate: 0.01\n",
            "MyMLP Accuracy: 0.9667, Train Time: 0.06s, Inference Time: 0.0001s\n",
            "Sklearn Accuracy: 1.0000, Train Time: 0.04s, Inference Time: 0.0014s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow Accuracy: 1.0000, Train Time: 8.76s, Inference Time: 0.2805s\n",
            "Keras Accuracy: 1.0000, Train Time: 10.54s, Inference Time: 0.2334s\n",
            "PyTorch Accuracy: 1.0000, Train Time: 0.10s, Inference Time: 0.0002s\n",
            "\n",
            "Конфигурация #2\n",
            "Архитектура: [(4,), (16, 'relu'), (16, 'relu'), (3, 'softmax')]\n",
            "Learning rate: 0.005\n",
            "MyMLP Accuracy: 0.9333, Train Time: 0.08s, Inference Time: 0.0001s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sklearn Accuracy: 1.0000, Train Time: 0.05s, Inference Time: 0.0012s\n",
            "TensorFlow Accuracy: 1.0000, Train Time: 9.69s, Inference Time: 0.3017s\n",
            "Keras Accuracy: 1.0000, Train Time: 10.35s, Inference Time: 0.2939s\n",
            "PyTorch Accuracy: 1.0000, Train Time: 0.11s, Inference Time: 0.0002s\n",
            "\n",
            "Конфигурация #3\n",
            "Архитектура: [(4,), (8, 'sigmoid'), (3, 'softmax')]\n",
            "Learning rate: 0.01\n",
            "MyMLP Accuracy: 0.9333, Train Time: 0.06s, Inference Time: 0.0001s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sklearn Accuracy: 0.9667, Train Time: 0.04s, Inference Time: 0.0011s\n",
            "TensorFlow Accuracy: 1.0000, Train Time: 9.27s, Inference Time: 0.3731s\n",
            "Keras Accuracy: 1.0000, Train Time: 12.27s, Inference Time: 0.6234s\n",
            "PyTorch Accuracy: 0.9000, Train Time: 0.27s, Inference Time: 0.0005s\n",
            "\n",
            "Конфигурация #4\n",
            "Архитектура: [(4,), (20, 'relu'), (10, 'sigmoid'), (3, 'softmax')]\n",
            "Learning rate: 0.001\n",
            "MyMLP Accuracy: 0.5000, Train Time: 0.23s, Inference Time: 0.0003s\n",
            "Sklearn Accuracy: 0.8333, Train Time: 0.09s, Inference Time: 0.0014s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow Accuracy: 1.0000, Train Time: 11.57s, Inference Time: 0.8877s\n",
            "Keras Accuracy: 1.0000, Train Time: 15.92s, Inference Time: 0.2938s\n",
            "PyTorch Accuracy: 0.8333, Train Time: 0.11s, Inference Time: 0.0003s\n",
            "\n",
            "Конфигурация #5\n",
            "Архитектура: [(4,), (32, 'relu'), (32, 'relu'), (3, 'softmax')]\n",
            "Learning rate: 0.01\n",
            "MyMLP Accuracy: 0.9333, Train Time: 0.09s, Inference Time: 0.0002s\n",
            "Sklearn Accuracy: 1.0000, Train Time: 0.06s, Inference Time: 0.0013s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow Accuracy: 1.0000, Train Time: 9.65s, Inference Time: 0.2721s\n",
            "Keras Accuracy: 0.9667, Train Time: 10.71s, Inference Time: 0.2689s\n",
            "PyTorch Accuracy: 1.0000, Train Time: 0.11s, Inference Time: 0.0002s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_cls_results = pd.DataFrame(results)\n",
        "df_cls_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "id": "8jtIN9gvZ0ZW",
        "outputId": "88b83824-2cc8-4ccd-93dd-f621668def35"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Model Config  Accuracy  Train Time (s)  Inference Time (s)\n",
              "0        MyMLP      1  0.966667        0.058401            0.000129\n",
              "1      Sklearn      1  1.000000        0.043781            0.001379\n",
              "2   TensorFlow      1  1.000000        8.762219            0.280457\n",
              "3        Keras      1  1.000000       10.539163            0.233379\n",
              "4      PyTorch      1  1.000000        0.095083            0.000221\n",
              "5        MyMLP      2  0.933333        0.082888            0.000129\n",
              "6      Sklearn      2  1.000000        0.053576            0.001154\n",
              "7   TensorFlow      2  1.000000        9.685921            0.301739\n",
              "8        Keras      2  1.000000       10.347505            0.293937\n",
              "9      PyTorch      2  1.000000        0.111446            0.000220\n",
              "10       MyMLP      3  0.933333        0.062167            0.000125\n",
              "11     Sklearn      3  0.966667        0.040040            0.001139\n",
              "12  TensorFlow      3  1.000000        9.271741            0.373064\n",
              "13       Keras      3  1.000000       12.267881            0.623382\n",
              "14     PyTorch      3  0.900000        0.272164            0.000478\n",
              "15       MyMLP      4  0.500000        0.230784            0.000275\n",
              "16     Sklearn      4  0.833333        0.091944            0.001429\n",
              "17  TensorFlow      4  1.000000       11.568753            0.887675\n",
              "18       Keras      4  1.000000       15.922600            0.293785\n",
              "19     PyTorch      4  0.833333        0.110015            0.000258\n",
              "20       MyMLP      5  0.933333        0.093843            0.000151\n",
              "21     Sklearn      5  1.000000        0.058742            0.001329\n",
              "22  TensorFlow      5  1.000000        9.647906            0.272088\n",
              "23       Keras      5  0.966667       10.709162            0.268852\n",
              "24     PyTorch      5  1.000000        0.108433            0.000242"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-40fe07f9-c998-4f70-a883-17ccaa1cbbd1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Config</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Train Time (s)</th>\n",
              "      <th>Inference Time (s)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MyMLP</td>\n",
              "      <td>1</td>\n",
              "      <td>0.966667</td>\n",
              "      <td>0.058401</td>\n",
              "      <td>0.000129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sklearn</td>\n",
              "      <td>1</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.043781</td>\n",
              "      <td>0.001379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TensorFlow</td>\n",
              "      <td>1</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8.762219</td>\n",
              "      <td>0.280457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Keras</td>\n",
              "      <td>1</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>10.539163</td>\n",
              "      <td>0.233379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PyTorch</td>\n",
              "      <td>1</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.095083</td>\n",
              "      <td>0.000221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>MyMLP</td>\n",
              "      <td>2</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>0.082888</td>\n",
              "      <td>0.000129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Sklearn</td>\n",
              "      <td>2</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.053576</td>\n",
              "      <td>0.001154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>TensorFlow</td>\n",
              "      <td>2</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>9.685921</td>\n",
              "      <td>0.301739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Keras</td>\n",
              "      <td>2</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>10.347505</td>\n",
              "      <td>0.293937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>PyTorch</td>\n",
              "      <td>2</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.111446</td>\n",
              "      <td>0.000220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>MyMLP</td>\n",
              "      <td>3</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>0.062167</td>\n",
              "      <td>0.000125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Sklearn</td>\n",
              "      <td>3</td>\n",
              "      <td>0.966667</td>\n",
              "      <td>0.040040</td>\n",
              "      <td>0.001139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>TensorFlow</td>\n",
              "      <td>3</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>9.271741</td>\n",
              "      <td>0.373064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Keras</td>\n",
              "      <td>3</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>12.267881</td>\n",
              "      <td>0.623382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>PyTorch</td>\n",
              "      <td>3</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.272164</td>\n",
              "      <td>0.000478</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>MyMLP</td>\n",
              "      <td>4</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.230784</td>\n",
              "      <td>0.000275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Sklearn</td>\n",
              "      <td>4</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.091944</td>\n",
              "      <td>0.001429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>TensorFlow</td>\n",
              "      <td>4</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>11.568753</td>\n",
              "      <td>0.887675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Keras</td>\n",
              "      <td>4</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>15.922600</td>\n",
              "      <td>0.293785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>PyTorch</td>\n",
              "      <td>4</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.110015</td>\n",
              "      <td>0.000258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>MyMLP</td>\n",
              "      <td>5</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>0.093843</td>\n",
              "      <td>0.000151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Sklearn</td>\n",
              "      <td>5</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.058742</td>\n",
              "      <td>0.001329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>TensorFlow</td>\n",
              "      <td>5</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>9.647906</td>\n",
              "      <td>0.272088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Keras</td>\n",
              "      <td>5</td>\n",
              "      <td>0.966667</td>\n",
              "      <td>10.709162</td>\n",
              "      <td>0.268852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>PyTorch</td>\n",
              "      <td>5</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.108433</td>\n",
              "      <td>0.000242</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-40fe07f9-c998-4f70-a883-17ccaa1cbbd1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-40fe07f9-c998-4f70-a883-17ccaa1cbbd1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-40fe07f9-c998-4f70-a883-17ccaa1cbbd1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4bb32e33-6b92-4621-b804-0221d516dc2b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4bb32e33-6b92-4621-b804-0221d516dc2b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4bb32e33-6b92-4621-b804-0221d516dc2b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_cls_results",
              "summary": "{\n  \"name\": \"df_cls_results\",\n  \"rows\": 25,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Sklearn\",\n          \"PyTorch\",\n          \"TensorFlow\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Config\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2\",\n          \"5\",\n          \"3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10633629514541473,\n        \"min\": 0.5,\n        \"max\": 1.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          1.0,\n          0.8333333333333334,\n          0.9666666666666667\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Train Time (s)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.5319956272133775,\n        \"min\": 0.040039777755737305,\n        \"max\": 15.922599792480469,\n        \"num_unique_values\": 25,\n        \"samples\": [\n          10.347505331039429,\n          0.09194445610046387,\n          0.05840134620666504\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Inference Time (s)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2300397954604635,\n        \"min\": 0.0001246929168701172,\n        \"max\": 0.8876748085021973,\n        \"num_unique_values\": 25,\n        \"samples\": [\n          0.29393720626831055,\n          0.0014290809631347656,\n          0.00012946128845214844\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка данных\n",
        "data = fetch_california_housing()\n",
        "X, y = data.data, data.target.reshape(-1, 1)\n",
        "scaler_X = StandardScaler()\n",
        "scaler_y = StandardScaler()\n",
        "X = scaler_X.fit_transform(X)\n",
        "y = scaler_y.fit_transform(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ],
      "metadata": {
        "id": "7_vlb-28FUR2"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Конфигурации сетей\n",
        "configs = [\n",
        "    {\"layers\": [(8, \"\"), (16, \"relu\"), (1, \"linear\")], \"lr\": 0.01},\n",
        "    {\"layers\": [(8, \"\"), (32, \"relu\"), (1, \"linear\")], \"lr\": 0.005},\n",
        "    {\"layers\": [(8, \"\"), (16, \"sigmoid\"), (1, \"linear\")], \"lr\": 0.01},\n",
        "    {\"layers\": [(8, \"\"), (64, \"relu\"), (1, \"linear\")], \"lr\": 0.001},\n",
        "    {\"layers\": [(8, \"\"), (32, \"sigmoid\"), (1, \"linear\")], \"lr\": 0.01},\n",
        "]"
      ],
      "metadata": {
        "id": "g8kul6pWFXcz"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "\n",
        "# MyMLP\n",
        "for idx, cfg in enumerate(configs):\n",
        "    print(f\"\\nMyMLP Config {idx+1}\")\n",
        "    mlp = MyMLP(cfg[\"layers\"], learning_rate=cfg[\"lr\"], task='regression', loss='mse')\n",
        "    start = time.time()\n",
        "    mlp.fit(X_train, y_train, epochs=50, batch_size=32)\n",
        "    train_time = time.time() - start\n",
        "\n",
        "    start = time.time()\n",
        "    y_pred = mlp.predict(X_test)\n",
        "    infer_time = time.time() - start\n",
        "\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    print(\"MyMLP MSE:\", mse)\n",
        "    results.append((\"MyMLP\", idx+1, mse, train_time, infer_time))\n",
        "\n",
        "# Sklearn MLPRegressor\n",
        "for idx, cfg in enumerate(configs):\n",
        "    print(f\"\\nSklearn Config {idx+1}\")\n",
        "    act = cfg[\"layers\"][1][1]\n",
        "    if act == 'sigmoid':\n",
        "        act = 'logistic'  # sklearn expects 'logistic' not 'sigmoid'\n",
        "\n",
        "    model = MLPRegressor(hidden_layer_sizes=[cfg[\"layers\"][1][0]], learning_rate_init=cfg[\"lr\"],\n",
        "                         max_iter=50, activation=act, random_state=42)\n",
        "\n",
        "    start = time.time()\n",
        "    model.fit(X_train, y_train.ravel())\n",
        "    train_time = time.time() - start\n",
        "\n",
        "    start = time.time()\n",
        "    y_pred = model.predict(X_test).reshape(-1, 1)\n",
        "    infer_time = time.time() - start\n",
        "\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    print(\"Sklearn MSE:\", mse)\n",
        "    results.append((\"Sklearn\", idx+1, mse, train_time, infer_time))\n",
        "\n",
        "# Keras\n",
        "for idx, cfg in enumerate(configs):\n",
        "    print(f\"\\nKeras Config {idx+1}\")\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.Input(shape=(8,)))\n",
        "    model.add(keras.layers.Dense(cfg[\"layers\"][1][0], activation=cfg[\"layers\"][1][1]))\n",
        "    model.add(keras.layers.Dense(1, activation='linear'))\n",
        "\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=cfg[\"lr\"]),\n",
        "                  loss='mse')\n",
        "\n",
        "    start = time.time()\n",
        "    model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0)\n",
        "    train_time = time.time() - start\n",
        "\n",
        "    start = time.time()\n",
        "    y_pred = model.predict(X_test)\n",
        "    infer_time = time.time() - start\n",
        "\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    print(\"Keras MSE:\", mse)\n",
        "    results.append((\"Keras\", idx+1, mse, train_time, infer_time))\n",
        "\n",
        "# TensorFlow (без Keras)\n",
        "for idx, cfg in enumerate(configs):\n",
        "    print(f\"\\nTensorFlow Config {idx+1}\")\n",
        "\n",
        "    # Модель вручную\n",
        "    layers_tf = []\n",
        "    input_dim = 8\n",
        "    for size, act in cfg[\"layers\"][1:]:\n",
        "        w = tf.Variable(tf.random.normal([input_dim, size], stddev=0.1))\n",
        "        b = tf.Variable(tf.zeros([size]))\n",
        "        layers_tf.append((w, b, act))\n",
        "        input_dim = size\n",
        "\n",
        "    def forward_tf(x):\n",
        "        for w, b, activation in layers_tf:\n",
        "            x = tf.matmul(x, w) + b\n",
        "            if activation == 'relu':\n",
        "                x = tf.nn.relu(x)\n",
        "            elif activation == 'sigmoid':\n",
        "                x = tf.nn.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "    X_tf = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
        "    y_tf = tf.convert_to_tensor(y_train, dtype=tf.float32)\n",
        "\n",
        "    optimizer = tf.optimizers.Adam(learning_rate=cfg[\"lr\"])\n",
        "\n",
        "    start = time.time()\n",
        "    for epoch in range(50):\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred_tf = forward_tf(X_tf)\n",
        "            loss = tf.reduce_mean(tf.square(y_pred_tf - y_tf))\n",
        "        grads = tape.gradient(loss, [v for w, b, _ in layers_tf for v in (w, b)])\n",
        "        optimizer.apply_gradients(zip(grads, [v for w, b, _ in layers_tf for v in (w, b)]))\n",
        "    train_time = time.time() - start\n",
        "\n",
        "    start = time.time()\n",
        "    y_pred = forward_tf(tf.convert_to_tensor(X_test, dtype=tf.float32)).numpy()\n",
        "    infer_time = time.time() - start\n",
        "\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    print(\"TensorFlow MSE:\", mse)\n",
        "    results.append((\"TensorFlow\", idx+1, mse, train_time, infer_time))\n",
        "\n",
        "# PyTorch\n",
        "for idx, cfg in enumerate(configs):\n",
        "    print(f\"\\nPyTorch Config {idx+1}\")\n",
        "\n",
        "    class PTModel(nn.Module):\n",
        "        def __init__(self, hidden_size, activation):\n",
        "            super().__init__()\n",
        "            act_fn = nn.ReLU() if activation == \"relu\" else nn.Sigmoid()\n",
        "            self.net = nn.Sequential(\n",
        "                nn.Linear(8, hidden_size),\n",
        "                act_fn,\n",
        "                nn.Linear(hidden_size, 1)\n",
        "            )\n",
        "\n",
        "        def forward(self, x):\n",
        "            return self.net(x)\n",
        "\n",
        "    model = PTModel(cfg[\"layers\"][1][0], cfg[\"layers\"][1][1])\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=cfg[\"lr\"])\n",
        "\n",
        "    X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
        "    y_train_t = torch.tensor(y_train, dtype=torch.float32)\n",
        "\n",
        "    start = time.time()\n",
        "    for epoch in range(50):\n",
        "        y_pred = model(X_train_t)\n",
        "        loss = criterion(y_pred, y_train_t)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    train_time = time.time() - start\n",
        "\n",
        "    start = time.time()\n",
        "    y_pred = model(torch.tensor(X_test, dtype=torch.float32)).detach().numpy()\n",
        "    infer_time = time.time() - start\n",
        "\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    print(\"PyTorch MSE:\", mse)\n",
        "    results.append((\"PyTorch\", idx+1, mse, train_time, infer_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYqPlOIqFZvU",
        "outputId": "c0c43689-a581-4557-83aa-240de2ff9406"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "MyMLP Config 1\n",
            "MyMLP MSE: 0.4092028159931907\n",
            "\n",
            "MyMLP Config 2\n",
            "MyMLP MSE: 0.42529071668109\n",
            "\n",
            "MyMLP Config 3\n",
            "MyMLP MSE: 0.4801592556363898\n",
            "\n",
            "MyMLP Config 4\n",
            "MyMLP MSE: 0.5346341545604963\n",
            "\n",
            "MyMLP Config 5\n",
            "MyMLP MSE: 0.404067684063224\n",
            "\n",
            "Sklearn Config 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sklearn MSE: 0.2531164353174806\n",
            "\n",
            "Sklearn Config 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sklearn MSE: 0.2834799524082856\n",
            "\n",
            "Sklearn Config 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sklearn MSE: 0.2510093796433167\n",
            "\n",
            "Sklearn Config 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sklearn MSE: 0.23504961677948658\n",
            "\n",
            "Sklearn Config 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sklearn MSE: 0.22999917882326631\n",
            "\n",
            "Keras Config 1\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Keras MSE: 0.24154899057946513\n",
            "\n",
            "Keras Config 2\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
            "Keras MSE: 0.7596289100646506\n",
            "\n",
            "Keras Config 3\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "Keras MSE: 0.2300449929176181\n",
            "\n",
            "Keras Config 4\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
            "Keras MSE: 0.23110923707398454\n",
            "\n",
            "Keras Config 5\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
            "Keras MSE: 0.22613819131616922\n",
            "\n",
            "TensorFlow Config 1\n",
            "TensorFlow MSE: 0.3372147643558983\n",
            "\n",
            "TensorFlow Config 2\n",
            "TensorFlow MSE: 0.36454499702916826\n",
            "\n",
            "TensorFlow Config 3\n",
            "TensorFlow MSE: 0.4644586692130046\n",
            "\n",
            "TensorFlow Config 4\n",
            "TensorFlow MSE: 0.615066300356943\n",
            "\n",
            "TensorFlow Config 5\n",
            "TensorFlow MSE: 0.41410006961027207\n",
            "\n",
            "PyTorch Config 1\n",
            "PyTorch MSE: 0.36261234098187445\n",
            "\n",
            "PyTorch Config 2\n",
            "PyTorch MSE: 0.3854758525539725\n",
            "\n",
            "PyTorch Config 3\n",
            "PyTorch MSE: 0.41511946428957824\n",
            "\n",
            "PyTorch Config 4\n",
            "PyTorch MSE: 0.5310148878134928\n",
            "\n",
            "PyTorch Config 5\n",
            "PyTorch MSE: 0.40070681514481443\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_results = pd.DataFrame(results, columns=[\"Model\", \"Config\", \"MSE\", \"Train Time (s)\", \"Infer Time (s)\"])\n",
        "df_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "id": "mfHYjRJYK6Bs",
        "outputId": "0276ee66-af28-4f59-806b-31cb4a2606f7"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Model  Config       MSE  Train Time (s)  Infer Time (s)\n",
              "0        MyMLP       1  0.409203        2.831436        0.002048\n",
              "1        MyMLP       2  0.425291        3.086981        0.024197\n",
              "2        MyMLP       3  0.480159        6.441232        0.002086\n",
              "3        MyMLP       4  0.534634        2.317252        0.004590\n",
              "4        MyMLP       5  0.404068        2.800491        0.003742\n",
              "5      Sklearn       1  0.253116        1.949555        0.001364\n",
              "6      Sklearn       2  0.283480        1.571037        0.001426\n",
              "7      Sklearn       3  0.251009        2.038174        0.002469\n",
              "8      Sklearn       4  0.235050        2.060202        0.002561\n",
              "9      Sklearn       5  0.229999        1.480460        0.004038\n",
              "10       Keras       1  0.241549       58.305836        0.704203\n",
              "11       Keras       2  0.759629       56.030070        0.383972\n",
              "12       Keras       3  0.230045       57.696344        0.365564\n",
              "13       Keras       4  0.231109       57.373821        0.362909\n",
              "14       Keras       5  0.226138       58.496171        0.283740\n",
              "15  TensorFlow       1  0.337215        1.484335        0.002145\n",
              "16  TensorFlow       2  0.364545        1.597907        0.002590\n",
              "17  TensorFlow       3  0.464459        1.451423        0.002216\n",
              "18  TensorFlow       4  0.615066        2.133402        0.004033\n",
              "19  TensorFlow       5  0.414100        2.245080        0.002733\n",
              "20     PyTorch       1  0.362612        0.154069        0.000501\n",
              "21     PyTorch       2  0.385476        0.202901        0.000624\n",
              "22     PyTorch       3  0.415119        0.127942        0.000670\n",
              "23     PyTorch       4  0.531015        0.476380        0.001314\n",
              "24     PyTorch       5  0.400707        0.245833        0.000735"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-70e21303-e492-4ca5-bfa3-81eb97b651de\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Config</th>\n",
              "      <th>MSE</th>\n",
              "      <th>Train Time (s)</th>\n",
              "      <th>Infer Time (s)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MyMLP</td>\n",
              "      <td>1</td>\n",
              "      <td>0.409203</td>\n",
              "      <td>2.831436</td>\n",
              "      <td>0.002048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MyMLP</td>\n",
              "      <td>2</td>\n",
              "      <td>0.425291</td>\n",
              "      <td>3.086981</td>\n",
              "      <td>0.024197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MyMLP</td>\n",
              "      <td>3</td>\n",
              "      <td>0.480159</td>\n",
              "      <td>6.441232</td>\n",
              "      <td>0.002086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MyMLP</td>\n",
              "      <td>4</td>\n",
              "      <td>0.534634</td>\n",
              "      <td>2.317252</td>\n",
              "      <td>0.004590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MyMLP</td>\n",
              "      <td>5</td>\n",
              "      <td>0.404068</td>\n",
              "      <td>2.800491</td>\n",
              "      <td>0.003742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Sklearn</td>\n",
              "      <td>1</td>\n",
              "      <td>0.253116</td>\n",
              "      <td>1.949555</td>\n",
              "      <td>0.001364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Sklearn</td>\n",
              "      <td>2</td>\n",
              "      <td>0.283480</td>\n",
              "      <td>1.571037</td>\n",
              "      <td>0.001426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Sklearn</td>\n",
              "      <td>3</td>\n",
              "      <td>0.251009</td>\n",
              "      <td>2.038174</td>\n",
              "      <td>0.002469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Sklearn</td>\n",
              "      <td>4</td>\n",
              "      <td>0.235050</td>\n",
              "      <td>2.060202</td>\n",
              "      <td>0.002561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Sklearn</td>\n",
              "      <td>5</td>\n",
              "      <td>0.229999</td>\n",
              "      <td>1.480460</td>\n",
              "      <td>0.004038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Keras</td>\n",
              "      <td>1</td>\n",
              "      <td>0.241549</td>\n",
              "      <td>58.305836</td>\n",
              "      <td>0.704203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Keras</td>\n",
              "      <td>2</td>\n",
              "      <td>0.759629</td>\n",
              "      <td>56.030070</td>\n",
              "      <td>0.383972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Keras</td>\n",
              "      <td>3</td>\n",
              "      <td>0.230045</td>\n",
              "      <td>57.696344</td>\n",
              "      <td>0.365564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Keras</td>\n",
              "      <td>4</td>\n",
              "      <td>0.231109</td>\n",
              "      <td>57.373821</td>\n",
              "      <td>0.362909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Keras</td>\n",
              "      <td>5</td>\n",
              "      <td>0.226138</td>\n",
              "      <td>58.496171</td>\n",
              "      <td>0.283740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>TensorFlow</td>\n",
              "      <td>1</td>\n",
              "      <td>0.337215</td>\n",
              "      <td>1.484335</td>\n",
              "      <td>0.002145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>TensorFlow</td>\n",
              "      <td>2</td>\n",
              "      <td>0.364545</td>\n",
              "      <td>1.597907</td>\n",
              "      <td>0.002590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>TensorFlow</td>\n",
              "      <td>3</td>\n",
              "      <td>0.464459</td>\n",
              "      <td>1.451423</td>\n",
              "      <td>0.002216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>TensorFlow</td>\n",
              "      <td>4</td>\n",
              "      <td>0.615066</td>\n",
              "      <td>2.133402</td>\n",
              "      <td>0.004033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>TensorFlow</td>\n",
              "      <td>5</td>\n",
              "      <td>0.414100</td>\n",
              "      <td>2.245080</td>\n",
              "      <td>0.002733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>PyTorch</td>\n",
              "      <td>1</td>\n",
              "      <td>0.362612</td>\n",
              "      <td>0.154069</td>\n",
              "      <td>0.000501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>PyTorch</td>\n",
              "      <td>2</td>\n",
              "      <td>0.385476</td>\n",
              "      <td>0.202901</td>\n",
              "      <td>0.000624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>PyTorch</td>\n",
              "      <td>3</td>\n",
              "      <td>0.415119</td>\n",
              "      <td>0.127942</td>\n",
              "      <td>0.000670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>PyTorch</td>\n",
              "      <td>4</td>\n",
              "      <td>0.531015</td>\n",
              "      <td>0.476380</td>\n",
              "      <td>0.001314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>PyTorch</td>\n",
              "      <td>5</td>\n",
              "      <td>0.400707</td>\n",
              "      <td>0.245833</td>\n",
              "      <td>0.000735</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-70e21303-e492-4ca5-bfa3-81eb97b651de')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-70e21303-e492-4ca5-bfa3-81eb97b651de button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-70e21303-e492-4ca5-bfa3-81eb97b651de');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-71cfcee9-d7ae-4719-93f7-7d46b27b4ae5\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-71cfcee9-d7ae-4719-93f7-7d46b27b4ae5')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-71cfcee9-d7ae-4719-93f7-7d46b27b4ae5 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_results",
              "summary": "{\n  \"name\": \"df_results\",\n  \"rows\": 25,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Sklearn\",\n          \"PyTorch\",\n          \"Keras\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Config\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2,\n          5,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MSE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1361707731517439,\n        \"min\": 0.22613819131616922,\n        \"max\": 0.7596289100646506,\n        \"num_unique_values\": 25,\n        \"samples\": [\n          0.23504961677948658,\n          0.36454499702916826,\n          0.4092028159931907\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Train Time (s)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 22.796868265600175,\n        \"min\": 0.12794232368469238,\n        \"max\": 58.49617099761963,\n        \"num_unique_values\": 25,\n        \"samples\": [\n          2.0602023601531982,\n          1.5979065895080566,\n          2.8314359188079834\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Infer Time (s)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.18281890063408218,\n        \"min\": 0.0005013942718505859,\n        \"max\": 0.7042028903961182,\n        \"num_unique_values\": 25,\n        \"samples\": [\n          0.002561330795288086,\n          0.002589702606201172,\n          0.002048492431640625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    }
  ]
}